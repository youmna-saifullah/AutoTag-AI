{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gme5s-Db0rOE"
      },
      "source": [
        "# Problem Statement\n",
        "Customer support teams often struggle with high volumes of incoming tickets. Manually reading and assigning categories is slow, prone to human error, and delays resolution times. There is a need for an automated system that can accurately categorize free-text tickets into predefined labels with high confidence.\n",
        "\n",
        "# Objective\n",
        "To build an AI-driven system that uses Large Language Models to automatically classify support tickets. The system will leverage Prompt Engineering (Zero-shot and Few-shot) and potentially Fine-tuning to predict the top 3 most likely categories for any given ticket, improving organizational efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpRcSbM54GBL"
      },
      "source": [
        "# Environment Setup & Data Loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVRWkI3C4IW2",
        "outputId": "a9fd87bd-7658-4e3b-c276-4e8cf1ad3c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.16.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA3YplYq4lmc"
      },
      "source": [
        "# Setup the Script & Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08SfSpkd4nB3",
        "outputId": "2c70991e-e49e-4d8d-daf5-d2189f9c9d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Success! Reliable dataset loaded.\n",
            "Total rows: 50\n",
            "\n",
            "Sample Categories found: ['sci.crypt' 'comp.sys.mac.hardware' 'sci.electronics'\n",
            " 'comp.sys.ibm.pc.hardware']\n",
            "\n",
            "--- Text Preview ---\n",
            "\n",
            "(a) To use for sensitive but not strategically important traffic,\n",
            "(b) if the system was cheap.\n",
            "\n",
            "For example, I don't own a cordless phone.  With Clipper, I would.  If the \n",
            "local men in blue really wa...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "try:\n",
        "    # 1. Fetch a subset of data that looks like support tickets\n",
        "    # Categories: Hardware, Electronics, Cryptography (Security), and Space (Tech)\n",
        "    categories = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
        "                  'sci.electronics', 'sci.crypt']\n",
        "\n",
        "    dataset = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    # 2. Convert to Dataframe\n",
        "    df = pd.DataFrame({\n",
        "        'text': dataset.data,\n",
        "        'actual_category': [dataset.target_names[t] for t in dataset.target]\n",
        "    })\n",
        "\n",
        "    # 3. Clean: Remove empty strings and take a small sample for testing\n",
        "    df = df[df['text'].str.strip() != \"\"]\n",
        "    df = df.head(50).reset_index(drop=True)\n",
        "\n",
        "    print(\"‚úÖ Success! Reliable dataset loaded.\")\n",
        "    print(f\"Total rows: {len(df)}\")\n",
        "    print(\"\\nSample Categories found:\", df['actual_category'].unique())\n",
        "    print(\"\\n--- Text Preview ---\")\n",
        "    print(df['text'].iloc[0][:200] + \"...\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Still hitting an error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9BOK3fs6ZqK"
      },
      "source": [
        "# Step 2: Connecting the LLM ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUPh6OZD6cOf",
        "outputId": "f0d6300a-39e8-40ce-91c6-b453e2546934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO974qu07QWC",
        "outputId": "537a97ab-db5b-48f1-81a5-8fdd0291005a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- TICKET TEXT ---\n",
            "\n",
            "Ergo, if your life is sufficiently boring, you have no need for privacy?\n",
            "\n",
            "(This is not meant to be personal, just the logical conclusion of your\n",
            "statement.)...\n",
            "\n",
            "--- TOP 3 PREDICTIONS (Groq) ---\n",
            "[\"Cryptography\", \"Other\", \"Electronics\"]\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "# 1. Initialize the Groq Client\n",
        "client = Groq(api_key=\"Your API Key \")\n",
        "\n",
        "def classify_ticket_top3_groq(ticket_text):\n",
        "    categories = [\"Cryptography\", \"IBM PC Hardware\", \"Mac Hardware\", \"Electronics\", \"Other\"]\n",
        "\n",
        "    # We use a system message for better \"instruction following\" in Llama models\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this support ticket and provide the TOP 3 most relevant categories from: {categories}\n",
        "\n",
        "    Ticket: \"{ticket_text}\"\n",
        "\n",
        "    Output format: Just a Python list of strings.\n",
        "    Example: [\"Category A\", \"Category B\", \"Category C\"]\n",
        "    \"\"\"\n",
        "\n",
        "    # Using llama-3.3-70b-versatile for high accuracy\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a specialized support ticket classifier. Output only the requested list format.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0, # Keep it deterministic for classification\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "# 2. Test Execution\n",
        "sample_id = 2\n",
        "sample_text = df['text'].iloc[sample_id]\n",
        "\n",
        "print(f\"--- TICKET TEXT ---\\n{sample_text[:200]}...\\n\")\n",
        "\n",
        "try:\n",
        "    prediction = classify_ticket_top3_groq(sample_text)\n",
        "    print(f\"--- TOP 3 PREDICTIONS (Groq) ---\\n{prediction}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSNb_kMz94rg"
      },
      "source": [
        "# Few-Shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XNG-3XJY959q"
      },
      "outputs": [],
      "source": [
        "# These are our 'Shots' (Examples)\n",
        "few_shot_examples = [\n",
        "    {\n",
        "        \"text\": \"I'm having trouble with my motherboard. The BIOS doesn't recognize the hard drive.\",\n",
        "        \"label\": \"IBM PC Hardware\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"Does anyone know how to implement RSA encryption in Python? I need to secure my messages.\",\n",
        "        \"label\": \"Cryptography\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"My Mac SE/30 is showing a checkerboard pattern on the screen. Is the logic board dead?\",\n",
        "        \"label\": \"Mac Hardware\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_4BN5n-9_x6",
        "outputId": "2081e4d0-197d-4b4a-a2c8-e1ac3c92dcd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- FEW-SHOT PREDICTIONS ---\n",
            "['Philosophy', 'Other', 'Other']\n"
          ]
        }
      ],
      "source": [
        "def classify_ticket_fewshot_groq(ticket_text):\n",
        "    categories = [\"Cryptography\", \"IBM PC Hardware\", \"Mac Hardware\", \"Electronics\", \"Other\"]\n",
        "\n",
        "    # Building the few-shot string\n",
        "    example_str = \"\"\n",
        "    for ex in few_shot_examples:\n",
        "        example_str += f\"Ticket: {ex['text']}\\nCategories: ['{ex['label']}', 'Other', 'Other']\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert technical support classifier.\n",
        "    Below are some examples of how to classify tickets into the top 3 categories.\n",
        "\n",
        "    {example_str}\n",
        "\n",
        "    Now, classify this new ticket:\n",
        "    Ticket: \"{ticket_text}\"\n",
        "\n",
        "    Output format: Just a Python list of strings.\n",
        "    Example: [\"Category 1\", \"Category 2\", \"Category 3\"]\n",
        "    \"\"\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a specialized support ticket classifier. Output only the requested list format.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "# Test it out!\n",
        "try:\n",
        "    fewshot_prediction = classify_ticket_fewshot_groq(sample_text)\n",
        "    print(\"--- FEW-SHOT PREDICTIONS ---\")\n",
        "    print(fewshot_prediction)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvJ0m97a-bVc"
      },
      "source": [
        "# Building the Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PdHQbod-c0P",
        "outputId": "f217f2e1-abf5-4d01-f6c7-fe5baa318b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.3.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.22)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "P196JDE8-hFh",
        "outputId": "97ec20ac-4bb3-44ec-eb93-62fd6b9b472d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-821819529.py:33: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://062a1f20786e88fa2f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://062a1f20786e88fa2f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import time\n",
        "from groq import Groq\n",
        "\n",
        "# 1. Initialize Client\n",
        "client = Groq(api_key=\"Your_Key\")\n",
        "\n",
        "def batch_process(file_obj, mode):\n",
        "    \"\"\"Reads a CSV, tags every row in the 'text' column, and returns a new CSV.\"\"\"\n",
        "    df = pd.read_csv(file_obj.name)\n",
        "\n",
        "    if 'text' not in df.columns:\n",
        "        return None, \"Error: CSV must have a column named 'text'\"\n",
        "\n",
        "    results = []\n",
        "    for index, row in df.iterrows():\n",
        "        # Choose function based on UI selection\n",
        "        if mode == \"Zero-Shot\":\n",
        "            tag = classify_ticket_top3_groq(row['text'])\n",
        "        else:\n",
        "            tag = classify_ticket_fewshot_groq(row['text'])\n",
        "\n",
        "        results.append(tag)\n",
        "        time.sleep(1) # Slow down to avoid 429 errors on free tier\n",
        "\n",
        "    df['predicted_tags'] = results\n",
        "    output_path = \"tagged_tickets.csv\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "    return output_path, \"Batch Processing Complete!\"\n",
        "\n",
        "# --- UI Layout ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üé´ SmartSupport Pro: Batch Tagger\")\n",
        "\n",
        "    with gr.Tab(\"Single Ticket\"):\n",
        "        ticket_input = gr.Textbox(label=\"Ticket Text\", lines=5)\n",
        "        single_mode = gr.Radio([\"Zero-Shot\", \"Few-Shot\"], value=\"Few-Shot\", label=\"Mode\")\n",
        "        btn_single = gr.Button(\"Tag Single\")\n",
        "        output_single = gr.Label(label=\"Predictions\")\n",
        "        btn_single.click(process_ticket, [ticket_input, single_mode], output_single)\n",
        "\n",
        "    with gr.Tab(\"Batch Processing (CSV)\"):\n",
        "        gr.Markdown(\"Upload a CSV with a column named **'text'**.\")\n",
        "        file_input = gr.File(label=\"Upload CSV\")\n",
        "        batch_mode = gr.Radio([\"Zero-Shot\", \"Few-Shot\"], value=\"Few-Shot\", label=\"Mode\")\n",
        "        btn_batch = gr.Button(\"Start Batch Process\")\n",
        "        file_output = gr.File(label=\"Download Tagged CSV\")\n",
        "        status_text = gr.Textbox(label=\"Status\")\n",
        "\n",
        "        btn_batch.click(batch_process, [file_input, batch_mode], [file_output, status_text])\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install groq python-dotenv gradio pandas\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from groq import Groq\n",
        "\n",
        "# --- 1. Load API Key Safely ---\n",
        "def load_key_from_file(filepath='env.txt'):\n",
        "    if os.path.exists(filepath):\n",
        "        with open(filepath, 'r') as f:\n",
        "            for line in f:\n",
        "                if 'GROQ_API_KEY' in line:\n",
        "                    return line.split('=')[1].strip()\n",
        "    return None\n",
        "\n",
        "api_key = load_key_from_file()\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "# --- 2. Classification Logic ---\n",
        "categories = [\"Cryptography\", \"IBM PC Hardware\", \"Mac Hardware\", \"Electronics\", \"Other\"]\n",
        "\n",
        "few_shot_examples = [\n",
        "    {\"text\": \"My motherboard isn't recognizing the HDD.\", \"label\": \"IBM PC Hardware\"},\n",
        "    {\"text\": \"How to implement RSA in Python?\", \"label\": \"Cryptography\"},\n",
        "    {\"text\": \"Mac SE/30 logic board repair tips.\", \"label\": \"Mac Hardware\"}\n",
        "]\n",
        "\n",
        "def get_prediction(text, mode):\n",
        "    example_str = \"\"\n",
        "    if mode == \"Few-Shot\":\n",
        "        for ex in few_shot_examples:\n",
        "            example_str += f\"Ticket: {ex['text']}\\nTags: ['{ex['label']}', 'Other', 'Other']\\n\\n\"\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "    {example_str}\n",
        "    Analyze this ticket and provide the TOP 3 categories from {categories}:\n",
        "    Ticket: \"{text}\"\n",
        "    Output: Just a Python list of strings.\n",
        "    \"\"\"\n",
        "    \n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a support tagger. Output only the list.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "# --- 3. UI Functions ---\n",
        "def single_tag_ui(text, mode):\n",
        "    return get_prediction(text, mode)\n",
        "\n",
        "def batch_tag_ui(file_obj, mode):\n",
        "    df = pd.read_csv(file_obj.name)\n",
        "    if 'text' not in df.columns:\n",
        "        return None, \"Error: Missing 'text' column.\"\n",
        "    \n",
        "    results = []\n",
        "    for t in df['text']:\n",
        "        results.append(get_prediction(t, mode))\n",
        "        time.sleep(0.5) # Anti-rate-limit\n",
        "        \n",
        "    df['top_3_tags'] = results\n",
        "    df.to_csv(\"tagged_results.csv\", index=False)\n",
        "    return \"tagged_results.csv\", \"Success: Processed all tickets.\"\n",
        "\n",
        "# --- 4. Launch Gradio ---\n",
        "with gr.Blocks(theme=gr.themes.Monochrome()) as demo:\n",
        "    gr.Markdown(\"# üöÄ AutoTag AI: Support Ticket Classifier\")\n",
        "    \n",
        "    with gr.Tab(\"Single Testing\"):\n",
        "        inp = gr.Textbox(label=\"Ticket Content\", lines=4)\n",
        "        m = gr.Radio([\"Zero-Shot\", \"Few-Shot\"], value=\"Few-Shot\", label=\"Mode\")\n",
        "        out = gr.Label(label=\"Top 3 Predictions\")\n",
        "        btn = gr.Button(\"Classify\")\n",
        "        btn.click(single_tag_ui, [inp, m], out)\n",
        "        \n",
        "    with gr.Tab(\"Batch Upload\"):\n",
        "        f_in = gr.File(label=\"Upload CSV (must have 'text' column)\")\n",
        "        m_b = gr.Radio([\"Zero-Shot\", \"Few-Shot\"], value=\"Few-Shot\")\n",
        "        f_out = gr.File(label=\"Download Result\")\n",
        "        status = gr.Textbox(label=\"Status\")\n",
        "        b_btn = gr.Button(\"Run Batch\")\n",
        "        b_btn.click(batch_tag_ui, [f_in, m_b], [f_out, status])\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
